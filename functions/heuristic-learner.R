library(here)
setwd(here())

source("functions.R")

#' @title Weak Learner
#'
#' @description 
#' Filters all possible rectangles to be only rectangles that both contain positive evidence and don't contain negative evidence. 
weakLearner = function(borders, #' @param borders Array of hypothesised category boundary points (coordinates of rectangles)
                       observations) { #' @param observations Matrix (or vector if only one point) of points that have been labeled as belonging to the true category or not (same input as heuristicLearner)
  isInRectPos = areInCat(borders, observations, "positive")
  areInRect = function(isInRect)
    setequal(isInRect, rep(TRUE, length(as.data.frame(isInRect))))
  positiveEvidence = if (length(as.data.frame(isInRectPos)) > 1) {
    # tells us which rectangles contain all of the observations of the category of interest
    apply(isInRectPos, 1, areInRect)
  } else {
    # if length is 1, no need to do the above function
    positiveEvidence = isInRectPos
  }
  
  isInRectNeg = areInCat(borders, observations, "negative") # does the hypothesised rectangle contain negative evidence?
  negativeEvidence = if (length(as.data.frame(isInRectPos)) > 1) {
    negativeEvidence = rowSums(isInRectNeg) > 0
  } else {
    negativeEvidence = isInRectNeg
  }
  
  hypotheses = cbind(borders, positiveEvidence, negativeEvidence)
  hypotheses = hypotheses[hypotheses[, "positiveEvidence"] == TRUE &
                            hypotheses[, "negativeEvidence"] == FALSE, ]
  hypotheses$likelihood = 1
  hypotheses$posterior = hypotheses[,"likelihood"]/sum(hypotheses[,"likelihood"]) # no prior yet so posterior is just likelihood over sum(likelihood)
  return(hypotheses)
}


#***** Least squares heuristic

#' @title Heuristic Learners
#' 
#' @description 
#' Calculates the probability of different rectangles for either the "least squares" or "outer" heuristic strategies. 
heuristicLearner = function(borders, #' @param borders Array of hypothesised category boundary points (coordinates of rectangles)
                            obs, #' @param obs Matrix of points that have been labelled as belonging to a certain category
                            heuristic = "least-squares") { #' @param heuristic Heuristic strategy to choose. "least-squares" chooses the rectangle that minimizes 
                            #' the distance between the nearest corner of the rectangle and the positive AND negative observations. "Outer" minimizes the distance 
                            #' between the corners and the negative evidence only (Andy's suggestion from meeting)
  # Identify consistent hypotheses 
  consistent =  weakLearner(borders, obs)
  
  if (heuristic == "outer"){ 
    obs = obs[obs[,"category"] == "negative",] # only difference between the "outer" and "LS" heuristics is that outer only considers the negative evidence. 
  }
  
  eDistance = function(point1, point2) {
    # euclidean distance formula: d = √[(x2 – x1)^2 + (y2 – y1)^2]
    sqrt((point2[1] - point1[1]) ^ 2 + (point2[2] - point1[2]) ^ 2)
  }
  

  
  #2 Rank hypotheses based on each point's proximity to the corners.
  #a. determine the coordinates of all of the corners:
  # For each eligible hypothesis, calculate all of the corners.
  meanDistances = NULL
  for (i in 1:length(consistent[, 1])) {
    # 1. get the coordinates of all of the corners
    xcoords = c(consistent[i, 1], consistent[i, 3])
    ycoords = c(consistent[i, 2], consistent[i, 4])
    corners = expand.grid(xcoords, ycoords)
    # 2. calculate the euclidean distance of each observation to each of the corners of each consistent hypothesis
    # - What is the distance from each observation to each corner, and then take the distance to its closest corner.
    distances = c()
    
    if (is.vector(obs)){
      nObs = 1
      for (j in 1:nObs) {
        obsDistances = eDistance(corners, as.numeric(obs[1:2]))
        minDistance = min(obsDistances)
        distances[j] = minDistance
      }
    } else {
      for (j in 1:length(obs[,1])) {
        obsDistances = eDistance(corners, as.numeric(obs[j, 1:2]))
        minDistance = min(obsDistances)
        distances[j] = minDistance
      }
    }
    

    meanDistances[i] = mean(distances) # average distance from each point to its nearest corner
  }
  
  hypotheses = cbind(consistent[1:4], meanDistances)
  colnames(hypotheses) = c("x1", "y1", "x2", "y2", "meanDistances")
  hypotheses$normalised = hypotheses$meanDistances / sum(hypotheses$meanDistances) # normalize so they are all between 0 and 1
  hypotheses$prob = (1 - hypotheses$normalised) / sum(1 - hypotheses$normalised) # Take from 1 so that the hypotheses with smallest distances have the highest probability
  return(hypotheses)
}

# plot

plotHeuristic = function(hypotheses,#' @param hypotheses Matrix including the posterior probability of each rectangle and their coordinates as generated by the heuristicLearner function. 
                         observations, #' @param observations Matrix (or vector if only one point) of points that have been labeled as belonging to the true category or not (same input as heuristicLearner)
                         trueRectangle, #' @param trueRectangle True rectangle
                         nHypotheses = "all", #' @param nHypotheses Number of hypotheses/rectangles to plot. E.g., nHypotheses = 1 means only the most probable rectangle is plotted. 
                         range = 1:10) { #' @param range Vector denoting the size of hypothesis space and discrete intervals
  
  if (nHypotheses == "all"){
    nHypotheses = length(hypotheses[,1])
  } else {
    nHypotheses = nHypotheses
  }
  
  hypotheses = hypotheses[order(hypotheses[,"prob"], decreasing = TRUE),]
  hypotheses = hypotheses[1:nHypotheses,]
  hypotheses[,"prob"] = hypotheses[,"prob"]/sum(hypotheses[,"prob"])
  
  plot(c(1,max(range)), c(1, max(range)), type= "n", xlab = "", ylab = "")
  rect(hypotheses[,1],hypotheses[,2],hypotheses[,3],hypotheses[,4], col= rgb(0,0,1,alpha=hypotheses[,"prob"]),lwd = 0.01)
  #) # making alpha equal t 1/the number of hypotheses makes the transparency of the plot equivilent to the relitive probability of each hypothesis. 
  points(observations)
  rect(trueRectangle[1],trueRectangle[2],trueRectangle[3],trueRectangle[4],border = "red", lwd = 2)
}
