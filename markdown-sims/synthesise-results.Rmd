---
title: "Results Synthesis"
author: "Manikya Aluster"
date: "2023-01-26"
output: 
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(here)
library(tidyverse)
library(ggpubr)

source(here("plottingFunctions.R"))
source(here("calculatingFunctions.R"))
source(here("plottingFunctions.R"))
load(here("experiment-1/data/derived/all_conditions.R"))
load(here("experiment-1/data/derived/data_cartesian.Rdata"))
```

I propose we use two main fgures to show our results: 

1. Heat maps of just the second target block (8th overall). The first target block is much the same in both conditions but just a bit messier, probably because people were still learning what to do. 

Experiment 1: 


```{r echo = FALSE, message = FALSE, results='hide',fig.keep='all'}
tb8 <- all_conditions %>% filter(targetBlocks == 8)
plotHeatMaps(d = d_cartesian, all_conditions = tb8)
```

Experiment 2

```{r message = FALSE, echo = FALSE, results='hide',fig.keep='all'}
load(here("experiment-2/data/derived/data_cartesian.Rdata"))
tb8 <- all_conditions %>% filter(targetBlocks == 8)
plotHeatMaps(d = d_cartesian, all_conditions = tb8)
```


I think that from these two plots you can see the main contrast between the experiments pretty clearly. In experiment 1, participants were generalizing more tightly in in the helpful cover story condition, but it was too unconstrained in the other conditions for them to know what to do. Once we provided feedback in Experiment 2, there was a much greater contrast between the helpful and non-helpful conditions, whereby people are clearely drawing larger rectangles in in the non-helpful conditions, but it's pretty variable, whereas people in the helpful conditions guess the strategy the teacher is using pretty much straight away.

You can also kind of see how, in the helpful condition, although people are slightly better at getting the strategy when there's a cover story, they are still very good when there is no cover story. This is true in both experiments, but much more so in experiment 2. Ultimately, I think experiment 2 just cleans up a lot of noise by constraining participant responses a little more. 

Some things the heat map doesn't do as clearly, in my opinion: 

1. The model predictions

I don't think theres a super easy weay to overlay the model predictions with this plot. 

2. The simplicity of the size rule in the models

Something that I think is quite interesting to me, is that the model actually makes a really simple prediction about the size of rectangle someone should draw given the condition. Positive points = smallest possible rectangle and negative points = largest possible rectangle for a helpful provider, then just reverse it if they're unhelpful. Despite this fairly simple rule, people still can't pick up on it. I think this contrast between the model predictions and participant behaviour could be shown nicely with a plot like the following, with the model predictions above the participant responses: 

```{r echo = FALSE, message = FALSE}
# load data
source(here("getLearnerHypDistributions.R"))
load(here("experiment-scenarios/target-blocks/data/target-block-8-Cartesian.Rdata"))
observations = targetBlock$observations

alphas <- c(-1,0,1)
clues <- c(4)
# Predicted distributions for each alpha 
all_dists = NULL
for (i in 1:length(alphas)){
  dist <- getLearnerHypDistribution(observations, alpha = alphas[i], prior = "flat")
  # convert to df (probably a better way than this)
  distDf <- NULL 
  for (j in clues){
    distBlock <- dist[[clues]]
    distDf <- rbind(distDf, distBlock)
  }
  all_dists <- rbind(all_dists,distDf)
  }

# plot
modelPredPlot <- all_dists %>%
  mutate(Alpha = as.factor(alpha)) %>%
  mutate(clue_name = case_when(
    clue == 1 ~ "1st Clue",
    clue == 4 ~ "4th Clue"
  ))%>%
  ggplot()+
  geom_line(aes(x = size, y = posterior, colour = Alpha))+
  scale_colour_manual(values = c("1" = "darkgreen", "0" = "lightblue", "-1" = "darkred"))+
  theme_classic()+
  ylim(c(0,0.05))+
  theme(
  legend.position = c(0.9, 0.8), # c(0,0) bottom left, c(1,1) top-right.
  legend.background = element_rect(fill = "white", colour = NA),
  legend.key.height = unit(0.25,"cm"),
  text = element_text(size = 6)
  )+
  labs(x = "Rectangle Size (increasing)", y = "Posterior", subtitle = "Model Predictions (4th Clue)")
  #facet_grid(~clue_name, scales = "free")

```


```{r message = FALSE}
# Size histograms

sizeHist = function(data){
  data %>%
    mutate(index = as.character(index)) %>%
    group_by(cond, size_resp) %>%
    arrange(size_resp) %>%
    ggplot()+
    labs(subtitle = "Participant Responses", x = "Rectangle Size (Increasing)")+
    geom_bar(aes(x = as.factor(size_resp), fill = cond), show.legend = FALSE)+
    scale_fill_manual(values = c("HS" = "darkgreen", "HN" = "darkgreen", "RS" = "lightblue", "RN" = "lightblue", "MS" = "darkred", "MN" = "darkred", "UN" = "orange", "US" = "orange"))+
    geom_vline(xintercept = "228", colour = "red")+
    theme_classic()+
    ylim(c(0,100))+
          theme(#axis.text.x=element_blank(),
            #axis.ticks.x=element_blank(),
            #axis.text.y=element_blank(),
            #axis.ticks.y=element_blank(),
            text = element_text(size = 4),
            strip.background = element_blank(),
            #plot.margin = margin(-1, 0, -1, 0, "cm"),
            strip.text = element_text(margin = margin(0,0,0,0, "cm"), size = 5))+
    facet_wrap(~cond+Experiment, ncol = 2)
}

load(here("experiment-1/data/derived/data_cartesian.Rdata"))
d_e1 = d_cartesian
d_e1$Experiment ="Experiment 1"

load(here("experiment-2/data/derived/data_cartesian.Rdata"))
d_e2 = d_cartesian
d_e2$Experiment = "Experiment 2"

d_combined = rbind(d_e1, d_e2) %>%
  filter(block %in% c(8) & clue == 4)




```

```{r message = FALSE, echo = FALSE, fig.width = 3, fig.height=1.5}
modelPredPlot
```

```{r message = FALSE, fig.width=3, fig.height= 4}
sizeHist(d_combined)
```


I think that this plot just gives a decent overview of what the difference between responding to a deceptive teacher (choosing large rectangles) and just random responding, compared to what people actually did. It shows that even though the strategy you'd need is quite simple according to the model, people couldn't figure it out. It's not really "fitting" the model like we pre-registered, I think I thought it would be clearer than it turned out, but I'm not sure I can think of any better alternative. 

A few things to note: 

1. The above plot is just for the 4th clue. I thought that would be the best tradeoff between informativeness and space. 

2.The participant response histograms are the counts of responses (I can't figure out how to get it to show proportions and didn't want to sink any more time on it for now), so bear in mind that there are actuaully fewer people in E2 overall.

2. I've deliberately made the plots kind of small to see what they would look like shrunk into the manuscript. 

### The other option for plotting the model I don't think is as good 

The original bar plots showing the fits to each alpha didn't work out as well as I hoped. I think there could be an issue with the way I calculate the summary statistics that go into the plot, but even though this analysis is probably the truest to how we pre-registered, I think it's a pretty bulky and not very intuitive plot overall. Here's block 8 for E1 and E2

E1: 

```{r fig.height=9}
load(here("experiment-1/modelling/04_output/tb8-all-alpha-posteriors.Rdata"))
exp = 1
sum = all_alpha_posteriors %>%
  group_by(alpha, cond, clue) %>%
  summarise(mean = mean(posterior), median = median(posterior), sum = sum(posterior)) %>%
  mutate(cond = factor(cond, levels = c("MS", "US", "RS", "HS", "MN", "UN", "RN", "HN")))

plotPosteriors(data = sum, exp = exp, statistic =  "median", 8)
```

E2: 


```{r fig.height=9}
load(here("experiment-2/modelling/04_output/tb8-all-alpha-posteriors.Rdata"))
exp = 2
sum = all_alpha_posteriors %>%
  group_by(alpha, cond, clue) %>%
  summarise(mean = mean(posterior), median = median(posterior), sum = sum(posterior)) %>%
  mutate(cond = factor(cond, levels = c("MS", "US", "RS", "HS", "MN", "UN", "RN", "HN")))

plotPosteriors(data = sum, exp = exp, statistic =  "median", 8)
```