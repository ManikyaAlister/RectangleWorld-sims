---
title: "Empirical Priors"
format: pdf
editor: visual
echo: false
warning: false
message: false
---

```{r}
rm(list = ls())
library(here)
library(patchwork)
library(tidyr)
library(ggpubr)

load(here("experiment-3/data/derived/data_priors_cartesian.Rdata"))
load(here("datafiles/x0to10y0to10.RData"))
source(here("plottingFunctions.R"))
source(here("calculatingFunctions.R"))
```

```{r}
# create helper functions

filter_priors = function(data, block, condition = c("HS", "MS", "US", "RS")) {
  b <- block
  prior <- data %>%
    filter(block %in% b & cond %in% condition) %>%
    select(x1, y1, x2, y2, size_resp, index, cond)
  prior
}

filter_empirical = function(data, block, clue, condition = c("HS", "MS", "US", "RS",)) {
  b <- block
  c <- clue
  prior <- data %>%
    filter(block %in% b & cond %in% condition, c %in% clue) %>%
    select(x1, y1, x2, y2, size_resp, index, cond)
  prior
}

prior_hist = function(data, hyp) {
  
  # rename column for consistency with data
  hyp$size_resp <- hyp$size
  
  hyp_freq <- hyp %>%
    group_by(size_resp) %>%
    summarise(drawn_count = n()) %>%
    mutate(size_resp = as.numeric(size_resp))
  
  hyp %>%
    ggplot(aes(x = size_resp)) +
    geom_bar(data = data)
    #geom_bar(colour = "blue")
    #geom_line(data = hyp_freq, aes(x = size_resp, y = drawn_count))
}

scaled_rectangle_sizes <- function(data, hyp) {
  # Rename column for consistency with data
  hyp$size_resp <- as.character(hyp$size)
  
  # Calculate the frequency of each drawn rectangle size
  drawn_rect_freq <- data %>%
    group_by(size_resp) %>%
    summarise(drawn_count = n())
  
  hyp_freq <- hyp %>%
    group_by(size_resp) %>%
    summarise(drawn_count = n()) %>%
    mutate(size_resp = as.numeric(size_resp))
  
  # Merge drawn rectangle frequencies with hyp data to get possible rectangle counts
  #combined_data <- merge(drawn_rect_freq, hyp_freq, by.x = "size_resp", by.y = "size_resp", all.x = TRUE)
  combined_data <- full_join(drawn_rect_freq, hyp_freq, by = "size_resp") %>%
    mutate(drawn_count.x = replace_na(drawn_count.x, 0))
  
  # Calculate the scaled frequencies
  combined_data$scaled_freq <- combined_data$drawn_count.x / combined_data$drawn_count.y
  combined_data
}

plotPriorHistScaled = function(scaled_data, scaled = TRUE){
  # Plot histogram
  ggplot(scaled_data, aes(x = size_resp, y = scaled_freq)) +
    geom_bar(stat = "identity", fill = "skyblue", color = "black") +
    labs(x = "Rectangle Size", y = "Scaled Frequency", title = "Histogram of Scaled Rectangles")
}

```

In experiment 3, we added a "clue 0", where people could indicate a rectangle that they thought could be the true rectangle before any clues were presented. The purposes of this was to try and get a group level estimate of participants' prior distributions. From a theoretical perspective, it makes sense to think about priors as a prior for rectangles of a particular size (since the likelihood of the model is based on a size rule). So here, we attempted to see whether people had a bias for rectangles of particular sizes (e.g., smaller rectangles, or larger rectangles). If participants had, for example, a strong prior for small rectangles, this could explain why participants did not draw rectangles that were as large as the model predicted.

Since some rectangle sizes were more common than others (e.g., there are 100 rectangles of size 1 but only 1 rectangle of size 100) we scaled the rectangles that participants drew based on how common that rectangle was (i.e., the base rate of that rectangle size). That way we could see whether people were drawing rectangles of a particular size more often than we would expect by chance, if they were just selecting a random rectangle. Additionally, we separated the priors by condition, to see whether the condition participants were in affected their priors.

```{r}
block = 8
getEmpiricalPriors = function(block){
prior_all <- filter_priors(d_priors_cartesian, 1:8) 
conds <- c("HS", "MS", "US", "RS")
condition_names <- c("Helpful", "Misleading Naive", "Misleading Aware", "Random")
plot_list <- list()
all_empirical_priors <- list()

for (i in 1:length(conds)){
  cond_i <- conds[i]
  cond_name_i <- condition_names[i]
  prior_i <- filter_priors(d_priors_cartesian,block, condition = cond_i)
  prior_scaled_i <- scaled_rectangle_sizes(prior_i, hyp) %>%
    rename("size" = "size_resp") 
  
# Calculate density
dens <- density(prior_scaled_i$size, weights = prior_scaled_i$scaled_freq)

# Extract x (sizes) and y (densities) values
sizes <- dens$x
densities <- dens$y

# Round the sizes to the nearest whole number
rounded_sizes <- round(sizes)

# Filter rounded sizes to be between 1 and 100
filtered_indices <- rounded_sizes >= 1 & rounded_sizes <= 100
filtered_sizes <- rounded_sizes[filtered_indices]
filtered_densities <- densities[filtered_indices]

# Combine sizes and densities into a data frame
density_data <- data.frame(size = filtered_sizes, density = filtered_densities)

# Ensure one density value per unique rectangle size
density_data <- density_data %>%
  group_by(size) %>%
  summarise(density = mean(density))

# save prior into list of all empirical priors
all_empirical_priors[[conds[i]]] <- density_data

# simplel plot to make sure it looks okay
#plot(density_data$size, density_data$density)

prior_scaled_i$cond <- cond_i

# plot prior for given condition
  dens_plot_i <- prior_scaled_i %>% 
    ggplot(aes(x = size, weight = scaled_freq)) +
    geom_density(aes(fill = cond), alpha = 0.5) +
        scale_fill_manual(values = c("HS" = "darkgreen", "HN" = "darkgreen", "RS" = "lightblue", "RN" = "lightblue", "MS" = "darkred", "MN" = "darkred", "UN" = "orange", "US" = "orange"))+
    labs(x = "Rectangle Size", y = "Density", title = cond_name_i) +
    #xlim(1,100)+
    #scale_x_continuous(values = seq(1,100,20))+
    theme_minimal()+
    theme(legend.position = "none", axis.title = element_text(size = 10))
  plot_list[[i]] <- dens_plot_i
}

save(all_empirical_priors, file = here(paste0("experiment-3/data/derived/empirical-prior-block-",block,".Rdata")))

#names(all_empirical_priors) <- conds
plot <- ggpubr::ggarrange(plotlist = plot_list, nrow = 1)
annotate_figure(plot, top = text_grob(paste0("Block ", block), face = "bold"))
}
```

# Block 8

The plots below show the density of rectangles of different sizes (from smallest to largest) drawn by participants at the beginning of block 8 before seeing any clues. We were most interested in block 8 because this block was the focus of all of our analyses. It also would not be appropriate to average the priors over all blocks, as it is reasonable to assume that participants' priors could evolve over the experiment as they have to guess different rectangles.

```{r}
# block 8
ep_plot_b8 <- getEmpiricalPriors(8)
ep_plot_b8 

```

It appears that across all three conditions, people were more likely to draw rectangles of certain sizes. Or in other words, at the group level, peoples' prior distributions were not flat. Interestingly, in the helpful condition, peoples' priors favored smaller rectangles, whereas in the other conditions, there was more of a preference for larger rectangles relative to what you would expect by chance. This is surprising since despite receiving different clues, the actual true rectangles that participants were guessing were the same across all scenarios, so they should not necessarily be biased to expect different sized rectangles in different conditions.

# Block 1

One explanation for the different priors in different conditions is that since in the helpful condition participants, on average, drew smaller rectangles around positive points, they just developed a reflex for drawing smaller rectangles. If this were the case, this prior should develop across blocks as they guessed more rectangles. Therefore, we can test this prediction by looking at the priors before the first block, as below.

```{r}
ep_plot_b1 <- getEmpiricalPriors(1)
ep_plot_b1
combined_plot <- ggarrange(ep_plot_b1, ep_plot_b8, nrow = 2)
ggsave(filename = here("experiment-3/modelling/12_empirical-priors/plots/empirical-prior-densities.png"), width = 10, height = 5)
```

The priors before block 1 reflect the same qualitative pattern across conditions as those in block 8, suggesting that these differences across conditions are unlikely to be due to a learned reflex. Another possibility is that some participants believed that in addition to choosing clues, the informant could choose the true rectangle as well. For example, in the helpful condition, it might make sense for a helpful informant to choose smaller rectangles, as they would be easier to guess. This is unexpected because we did not provide any instructions that should have indicate that the informant chooses the rectangles. Regardless, if it was the case that they had this assumption, it does not affect the conclusions of the modelling. As shown below, model predictions using these empirical priors are very similar to those with flat priors.

# Model Predictions with Empirical vs. Flat Priors

We have shown that the group level prior distributions do not appear to resemble a flat prior (where all rectangles have equal probability). In this analysis we checked whether these different priors resulted in predictions that were substantially different to the flat priors we reported in the main analyses.

**Solid lines** are the model predictions with the empirical priors, **dashed lines** are the model predictions with flat priors.

```{r}
load(here("experiment-3/data/derived/plot-files-empirical.Rdata"))

# give names to the plot list based on the order that it's in alrady
names(plot_list) <- c("MS", "US","RS","HS")

conds <- c("HS", "MS", "US", "RS")

plot_list[order(match(names(plot_list), conds))]

man_plot <- ggpubr::ggarrange(plot_list[["HS"]], plot_list[["MS"]], plot_list[["US"]], plot_list[["RS"]], label.x = 0.1, nrow = 2, ncol = 2, common.legend = TRUE, legend = "top", font.label = list(size = 30))

ggsave(filename = here("experiment-3/modelling/12_empirical-priors/plots/size-hist-priors.png"), width = 20, height = 10, plot = man_plot)

```

Despite the fact the empirical priors differed from the flat priors, the predictions that both sets of models made were quite similar. If anything, the flat prior models seemed to predict participant behavior better.
