plotData2$obsCond = 2
plotData3 = allObs[allObs[,"nObsCond"]<=3,]
plotData3$obsCond = 3
plotData = rbind(plotData1, plotData2, plotData3)
ggplot(data = plotData) +
geom_rect(aes(xmin = x1, xmax = x2, ymin = y1, ymax = y2), colour = "black", alpha = 0)+
geom_point(aes(x = x, y = y, colour = category))+
labs(title = "Trial Configurations")+
theme_bw()+
theme(axis.text = element_blank(), panel.grid = element_line(colour = "grey", linetype = 1))+
scale_x_discrete(limits = factor(0:10)) +
scale_y_discrete(limits = factor(0:10)) +
facet_wrap(~`Unique Rectangle`+obsCond)
# plot
plotData1 = allObs[allObs[,"nObsCond"]==1,]
plotData1$obsCond = 1
plotData2 = allObs[allObs[,"nObsCond"]<=2,]
plotData2$obsCond = 2
plotData3 = allObs[allObs[,"nObsCond"]<=3,]
plotData3$obsCond = 3
plotData = rbind(plotData1, plotData2, plotData3)
ggplot(data = plotData) +
geom_rect(aes(xmin = x1, xmax = x2, ymin = y1, ymax = y2), colour = "black", alpha = 0)+
geom_point(aes(x = x, y = y, colour = category))+
labs(title = "Trial Configurations")+
theme_bw()+
theme(axis.text = element_blank(), panel.grid = element_line(colour = "grey", linetype = 1))+
scale_x_discrete(limits = factor(0:10)) +
scale_y_discrete(limits = factor(0:10)) +
facet_wrap(~`Unique Rectangle`+obsCond)
p1 = simulatePar(observations = allObs,borders = borders)
View(allObs)
nTriangles = 3
nTriangles = 3
nPos = c(1,2,3)
nNeg = c(1,2,3)
length(nPos)
allP = NULL
for (j in 1: nTriangles) {
for ( i in 1:length(nPos)){
observations = allobs[allObs[,"nObsCond"] == j & allObs[,"Unique Rectangle"] == i, ]
trial = c(j,i)
p = cbind(simulatePar(observations = allObs,borders = borders), trial)
allP =  rbind(allP, p)
}
}
for (j in 1: nTriangles) {
for ( i in 1:length(nPos)){
observations = allObs[allObs[,"nObsCond"] == j & allObs[,"Unique Rectangle"] == i, ]
trial = c(j,i)
p = cbind(simulatePar(observations = allObs,borders = borders), trial)
allP =  rbind(allP, p)
}
}
allP = NULL
for (j in 1: nTriangles) {
for ( i in 1:length(nPos)){
observations = allObs[allObs[,"nObsCond"] == j & allObs[,"Unique Rectangle"] == i, ]
trial = c(j,i)
p = cbind(simulatePar(observations = observations,borders = borders), trial)
allP =  rbind(allP, p)
}
}
View(allP)
for (j in 1: nTriangles) {
for ( i in 1:length(nPos)){
observations = allObs[allObs[,"nObsCond"] == i & allObs[,"Unique Rectangle"] == j, ]
trial = c(j,i)
p = cbind(simulatePar(observations = observations,borders = borders), trial)
allP =  rbind(allP, p)
}
}
View(allP)
View(observations)
View(allObs)
a1Large22Fit
knitr::opts_chunk$set(echo = TRUE)
source("optimiseAlpha.R")
borders = makeBorders(0:10)
knitr::opts_chunk$set(echo = TRUE)
source("optimiseAlpha.R")
borders = makeBorders(0:10)
# small rectangle
smallRect = c(2,2,4,4)
# 1 positive 1 negative, small
obs11small = generateObs(1,1,smallRect)
# grid search
gridSmall11 = alphaGridSearch(borders, obs11small)
# trusting participant
a1Small11 = simulatePar(obs11small, borders, alpha = 1)
# weak sampling assumptions participant
a0Small11 = simulatePar(obs11small, borders, alpha = 0)
# suspicious participant
aNeg1Small11 = simulatePar(obs11small, borders, alpha = -1)
par(mfrow = c(1,3))
# estimate alphas
a1Small11Fit = fitAlpha(a1Small11, gridSmall11)
plot(a1Small11Fit[,"alpha"], a1Small11Fit[,"prob"])
lines(a1Small11Fit[,"alpha"], a1Small11Fit[,"prob"])
a0Small11Fit = fitAlpha(a0Small11, gridSmall11)
plot(a0Small11Fit[,"alpha"], a0Small11Fit[,"prob"])
lines(a0Small11Fit[,"alpha"], a0Small11Fit[,"prob"])
aNeg1Small11Fit = fitAlpha(aNeg1Small11, gridSmall11)
plot(aNeg1Small11Fit[,"alpha"], aNeg1Small11Fit[,"prob"])
lines(x = aNeg1Small11Fit[,"alpha"], y = aNeg1Small11Fit[,"prob"])
# small rectangle
smallRect = c(2,2,4,4)
# 1 positive 1 negative, small
obs22small = generateObs(2,2,smallRect)
# grid search
gridSmall22 = alphaGridSearch(borders, obs22small)
# trusting participant
a1Small22 = simulatePar(obs22small, borders, alpha = 1)
# weak sampling assumptions participant
a0Small22 = simulatePar(obs22small, borders, alpha = 0)
# suspicious participant
aNeg1Small22 = simulatePar(obs22small, borders, alpha = -1)
par(mfrow = c(1,3))
# estimate alphas
a1Small22Fit = fitAlpha(a1Small22, gridSmall22)
plot(a1Small22Fit[,"alpha"], a1Small22Fit[,"prob"])
lines(a1Small22Fit[,"alpha"], a1Small22Fit[,"prob"])
a0Small22Fit = fitAlpha(a0Small22, gridSmall22)
plot(a0Small22Fit[,"alpha"], a0Small22Fit[,"prob"])
lines(a0Small22Fit[,"alpha"], a0Small22Fit[,"prob"])
aNeg1Small22Fit = fitAlpha(aNeg1Small22, gridSmall22)
plot(aNeg1Small22Fit[,"alpha"], aNeg1Small22Fit[,"prob"])
lines(x = aNeg1Small22Fit[,"alpha"], y = aNeg1Small22Fit[,"prob"])
# small rectangle
largeRect = c(2,2,9,9)
# 1 positive 1 negative, Large
obs11Large = generateObs(1,1,largeRect)
# grid search
gridLarge11 = alphaGridSearch(borders, obs11Large)
# trusting participant
a1Large11 = simulatePar(obs11Large, borders, alpha = 1)
# weak sampling assumptions participant
a0Large11 = simulatePar(obs11Large, borders, alpha = 0)
# suspicious participant
aNeg1Large11 = simulatePar(obs11Large, borders, alpha = -1)
par(mfrow = c(1,3))
# estimate alphas
a1Large11Fit = fitAlpha(a1Large11, gridLarge11)
plot(a1Large11Fit[,"alpha"], a1Large11Fit[,"prob"])
lines(a1Large11Fit[,"alpha"], a1Large11Fit[,"prob"])
a0Large11Fit = fitAlpha(a0Large11, gridLarge11)
plot(a0Large11Fit[,"alpha"], a0Large11Fit[,"prob"])
lines(a0Large11Fit[,"alpha"], a0Large11Fit[,"prob"])
aNeg1Large11Fit = fitAlpha(aNeg1Large11, gridLarge11)
plot(aNeg1Large11Fit[,"alpha"], aNeg1Large11Fit[,"prob"])
lines(x = aNeg1Large11Fit[,"alpha"], y = aNeg1Large11Fit[,"prob"])
# Large rectangle
largeRect = c(2,2,4,4)
# 1 positive 1 negative, Large
obs22Large = generateObs(2,2,largeRect)
# grid search
gridLarge22 = alphaGridSearch(borders, obs22Large)
# trusting participant
a1Large22 = simulatePar(obs22Large, borders, alpha = 1)
# weak sampling assumptions participant
a0Large22 = simulatePar(obs22Large, borders, alpha = 0)
# suspicious participant
aNeg1Large22 = simulatePar(obs22Large, borders, alpha = -1)
par(mfrow = c(1,3))
# estimate alphas
a1Large22Fit = fitAlpha(a1Large22, gridLarge22)
plot(a1Large22Fit[,"alpha"], a1Large22Fit[,"prob"])
lines(a1Large22Fit[,"alpha"], a1Large22Fit[,"prob"])
a0Large22Fit = fitAlpha(a0Large22, gridLarge22)
plot(a0Large22Fit[,"alpha"], a0Large22Fit[,"prob"])
lines(a0Large22Fit[,"alpha"], a0Large22Fit[,"prob"])
aNeg1Large22Fit = fitAlpha(aNeg1Large22, gridLarge22)
plot(aNeg1Large22Fit[,"alpha"], aNeg1Large22Fit[,"prob"])
lines(x = aNeg1Large22Fit[,"alpha"], y = aNeg1Large22Fit[,"prob"])
gridLargeLarger = alphaGridSearch(borders,obs11Large, alphaRange = seq(-5,5,1))
a5Large = simulatePar(obs11Large, borders, alpha = 5)
a5FitLarge =fitAlpha(a5Large, gridLargeLarger)
a5FitLarge
plotAlphaPredictions(gridSmall11, obs11small)
plotAlphaPredictions(gridSmall11, obs11small, smallRect)
gobsTest = enerateObs(1,1,smallRect)
gobsTest = generateObs(1,1,smallRect)
plot(gobsTest)
plot(gobsTest[,1:2])
pedLearner(borders, gobsTest)
learner = pedLearner(borders, gobsTest)
View(learner)
View(learner)
plotPed(learner, gobsTest, smallRect)
rect(0,0,10,5)
rect(0,0,10,5, col = "red")
plotPed(learner, gobsTest, smallRect)
rect(2,3,3,4, col = "red", alpha = 0.5)
source("functions/pedagogical-learner.R")
source("functions/generic-functions.R")
source("functions/samplingFunctions.R")
source("~/cloudstor/Sampas-gen/simulations/rectangle-world/functions/pedagogical-learner.R", echo=TRUE)
source("~/cloudstor/Sampas-gen/simulations/rectangle-world/functions/pedegogical-teacher.R", echo=TRUE)
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
library(here)
source(here("functions/heuristic-learner.R"))
library(here)
here()
source(here("functions/heuristic-learner.R"))
source(here("functions/pedagogical-learner.R"))
source(here("functions/generic-functions.R"))
source("~/cloudstor/Sampas-gen/simulations/rectangle-world/functions/pedagogical-learner.R", echo=TRUE)
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
library(here)
source(here("functions/heuristic-learner.R"))
set.seed(123)
# Define range of possible features
range = 1:10
# set up all possible hypotheses
borders = makeBorders(range)
source("~/cloudstor/Sampas-gen/simulations/rectangle-world/functions/pedagogical-learner.R", echo=TRUE)
source(here("functions/generic-functions.R"))
set.seed(123)
# Define range of possible features
range = 1:10
# set up all possible hypotheses
borders = makeBorders(range)
# Define the true category region
trueRectangle = c(2,2,6,8)
#visualize true category region
plot(c(1,max(range)), c(1, max(range)), type= "n", xlab = "", ylab = "")
rect(trueRectangle[1],trueRectangle[2],trueRectangle[3],trueRectangle[4],border = "red", lwd = 3)
obs = sampleRect(5,5,trueRectangle)
# set up different arrays with different numbers of observations
obs1 = obs[c(1,6),]
obs3 = obs[c(1:3,6:9),]
obs5 = obs[c(1:5,6:10),]
# visualize observations
plot(c(1,max(range)), c(1, max(range)), type= "n", xlab = "", ylab = "", main = "Hypothesis Space, Observations, and True Category Boundary")
rect(trueRectangle[1],trueRectangle[2],trueRectangle[3],trueRectangle[4],border = "red", lwd = 2)
points(obs5)
weak1 = pedLearner(borders, obs1, alpha = 0)
weak3 = pedLearner(borders, obs3, alpha = 0)
weak5 = pedLearner(borders, obs5, alpha = 0)
ped1 = pedLearner(borders, obs1)
ped3 = pedLearner(borders, obs3)
ped5 = pedLearner(borders, obs5)
plot(ped1[,"posterior"])
plot(1:length(ped1[,1],ped1[,"posterior"])
)
plot(1:length(ped1[,1]),ped1[,"posterior"])
View(ped1)
plot(1:length(ped1[,1]),order(ped1[,"posterior"]))
plot(1:length(ped1[,1]),ped1[order(ped1[,"posterior"]),"posterior"])
plot(1:length(ped1[,1]),ped1[order(ped1[,"posterior"]),"posterior"], "l")
plot(1:length(ped1[,1]),ped1[order(ped1[,"posterior"]),"posterior"], type = "l")
plot(ped1[order(ped1[,"sizePos"]),"posterior"],ped1[,"posterior"], type = "l")
plot(ped1[order(ped1[,"sizePos"]),"sizePos"],ped1[,"posterior"])
plot(1:length(ped1[,1]),ped1[order(ped1[,"posterior"]),"posterior"], type = "l")
plot(1:length(weak1[,1]),ped1[order(weak1[,"posterior"]),"posterior"], type = "l")
plot(1:length(weak1[,1]),ped1[order(weak1[,"posterior"]),"posterior"])
View(weak3)
ped1[order(weak1[,"posterior"]),"posterior"]
order(weak1[,"posterior"])
ped1[order(weak1[,"posterior"]),"posterior"]
plot(1:length(weak1[,1]),ped1[sort(weak1[,"posterior"]),"posterior"])
sort(weak1[,"posterior"])
plot(1:length(weak1[,1]),sort(weak1[,"posterior"]))
plot(1:length(ped1[,1]),sort(ped1[,"posterior"]), type = "l")
plot(1:length(ped5[,1]),sort(ped5[,"posterior"]), type = "l")
plot(1:length(weak5[,1]),sort(weak5[,"posterior"]))
plot(1:length(weak5[,1]),sort(weak5[,"posterior"]), "L")
plot(1:length(weak5[,1]),sort(weak5[,"posterior"]), "l")
plot(1:length(weak1[,1]),sort(weak1[,"posterior"]), "l")
ped1[sort(ped1[,"sizePos"]),"posterior"]
plot(sort(ped1[,"sizePos"]),ped1[sort(ped1[,"sizePos"]),"posterior"])
plot(sort(ped1[,"sizePos"]),ped1[sort(ped1[,"sizePos"]),"posterior"], "l")
par(mfrow(c(4,2)))
?par
par(mfcol(c(4,2)))
par(mfrow =(c(4,2)))
par(mfrow =(c(4,2)))
plot(1:length(ped1[,1]),sort(ped1[,"posterior"]), type = "l")
plot(1:length(weak1[,1]),sort(weak1[,"posterior"]), "l")
plot(1:length(ped5[,1]),sort(ped5[,"posterior"]), type = "l")
plot(1:length(weak5[,1]),sort(weak5[,"posterior"]), "l")
plot(sort(ped1[,"sizePos"]),ped1[sort(ped1[,"sizePos"]),"posterior"], "l")
par(mfrow =(c(3,2)))
plot(1:length(ped1[,1]),sort(ped1[,"posterior"]), type = "l")
plot(1:length(weak1[,1]),sort(weak1[,"posterior"]), "l")
plot(1:length(ped5[,1]),sort(ped5[,"posterior"]), type = "l")
plot(1:length(weak5[,1]),sort(weak5[,"posterior"]), "l")
#plot(sort(ped1[,"sizePos"]),ped1[sort(ped1[,"sizePos"]),"posterior"], "l")
par(mfrow =(c(3,2)))
plot(1:length(ped1[,1]),sort(ped1[,"posterior"]), type = "l")
plot(1:length(weak1[,1]),sort(weak1[,"posterior"]), "l")
plot(1:length(ped5[,1]),sort(ped5[,"posterior"]), type = "l")
plot(1:length(weak5[,1]),sort(weak5[,"posterior"]), "l")
plot(sort(ped1[,"sizePos"]),ped1[sort(ped1[,"sizePos"]),"posterior"], "l")
obs1
obs = obs1[1,]
source("functions/optimiseAlpha.R")
grid = alphaGridSearch(borders, obs)
View(grid)
View(alphaGridSearch)
alphaGridSearchDist = function(borders,
observations,
alphaRange = seq(from = -1, to = 1, by = .2),
prior = "uniform") {
gridSearch = NULL
for (i in 1:length(alphaRange)) {
rect =  pedLearner(borders, observations, prior, alpha = alphaRange[i]) # generate all eligible rectangles (hypotheses)
#orderedRect =  order(rect[, "posterior"], decreasing = TRUE) # order from highest to lowest probability
#bestRect = rect[rect[, "posterior"] == rect[orderedRect[1], "posterior"], 1:4] # take the most probable rectangle, keeping only the coordinate information (columns 1:4)
#posterior = rect[rect[, "posterior"] == rect[orderedRect[1], "posterior"], "posterior"] # probs a more efficient way to do this
alpha = rep(alphaRange[i], length(rect[, 1]))
#prob = rep(1 / length(bestRect[, 1]), length(bestRect[, 1])) # "prob" is necessary because in some scenarios a given alpha will say that multiple rectangles are most likely. For example,
# when alpha = 0, all eligible rectangles are equally possible. Therefore, "prob" corresponds to 1/no. of unique "best" rectangles at that alpha level. This way even though if an alpha of 1
# and an alpha of 0 both predict the same rectangle to be the best, we will say that it corresponds to alpha = 1 because there were fewer possible rectangles to match with.
rect = cbind(rect, alpha) # add a column so we know what alpha generated each rectangle
gridSearch = rbind(gridSearch, bestRect)
}
colnames(gridSearch) = c("x1", "y1", "x2", "y2", "posterior", "alpha", "prob") # name
return(gridSearch)
}
gridDist = alphaGridSearchDist(borders,obs)
alphaGridSearchDist = function(borders,
observations,
alphaRange = seq(from = -1, to = 1, by = .2),
prior = "uniform") {
gridSearch = NULL
for (i in 1:length(alphaRange)) {
rect =  pedLearner(borders, observations, prior, alpha = alphaRange[i]) # generate all eligible rectangles (hypotheses)
#orderedRect =  order(rect[, "posterior"], decreasing = TRUE) # order from highest to lowest probability
#bestRect = rect[rect[, "posterior"] == rect[orderedRect[1], "posterior"], 1:4] # take the most probable rectangle, keeping only the coordinate information (columns 1:4)
#posterior = rect[rect[, "posterior"] == rect[orderedRect[1], "posterior"], "posterior"] # probs a more efficient way to do this
alpha = rep(alphaRange[i], length(rect[, 1]))
#prob = rep(1 / length(bestRect[, 1]), length(bestRect[, 1])) # "prob" is necessary because in some scenarios a given alpha will say that multiple rectangles are most likely. For example,
# when alpha = 0, all eligible rectangles are equally possible. Therefore, "prob" corresponds to 1/no. of unique "best" rectangles at that alpha level. This way even though if an alpha of 1
# and an alpha of 0 both predict the same rectangle to be the best, we will say that it corresponds to alpha = 1 because there were fewer possible rectangles to match with.
rect = cbind(rect, alpha) # add a column so we know what alpha generated each rectangle
gridSearch = rbind(gridSearch, rect)
}
colnames(gridSearch) = c("x1", "y1", "x2", "y2", "posterior", "alpha", "prob") # name
return(gridSearch)
}
alphaGridSearchDist = function(borders,
observations,
alphaRange = seq(from = -1, to = 1, by = .2),
prior = "uniform") {
gridSearch = NULL
for (i in 1:length(alphaRange)) {
rect =  pedLearner(borders, observations, prior, alpha = alphaRange[i]) # generate all eligible rectangles (hypotheses)
#orderedRect =  order(rect[, "posterior"], decreasing = TRUE) # order from highest to lowest probability
#bestRect = rect[rect[, "posterior"] == rect[orderedRect[1], "posterior"], 1:4] # take the most probable rectangle, keeping only the coordinate information (columns 1:4)
#posterior = rect[rect[, "posterior"] == rect[orderedRect[1], "posterior"], "posterior"] # probs a more efficient way to do this
alpha = rep(alphaRange[i], length(rect[, 1]))
#prob = rep(1 / length(bestRect[, 1]), length(bestRect[, 1])) # "prob" is necessary because in some scenarios a given alpha will say that multiple rectangles are most likely. For example,
# when alpha = 0, all eligible rectangles are equally possible. Therefore, "prob" corresponds to 1/no. of unique "best" rectangles at that alpha level. This way even though if an alpha of 1
# and an alpha of 0 both predict the same rectangle to be the best, we will say that it corresponds to alpha = 1 because there were fewer possible rectangles to match with.
rect = cbind(rect, alpha) # add a column so we know what alpha generated each rectangle
gridSearch = rbind(gridSearch, rect)
}
colnames(gridSearch) = c("x1", "y1", "x2", "y2", "posterior", "alpha", "prob") # name
return(gridSearch)
}
gridDist = alphaGridSearchDist(borders,obs)
View(gridDist)
rect = c(2,2,4,4)
gridDist[gridDist[,1] == 2 & gridDist[,2] == 2 & gridDist[,3] == 4 & gridDist[,4] == 5  ]
gridDist[gridDist[,1] == 2 & gridDist[,2] == 2 & gridDist[,3] == 4 & gridDist[,4] == 5,]
match = gridDist[gridDist[,1] == 2 & gridDist[,2] == 2 & gridDist[,3] == 4 & gridDist[,4] == 4,]
View(match)
alphaGridSearchDist = function(borders,
observations,
alphaRange = seq(from = -1, to = 1, by = .2),
prior = "uniform") {
gridSearch = NULL
for (i in 1:length(alphaRange)) {
rect =  pedLearner(borders, observations, prior, alpha = alphaRange[i]) # generate all eligible rectangles (hypotheses)
#orderedRect =  order(rect[, "posterior"], decreasing = TRUE) # order from highest to lowest probability
#bestRect = rect[rect[, "posterior"] == rect[orderedRect[1], "posterior"], 1:4] # take the most probable rectangle, keeping only the coordinate information (columns 1:4)
#posterior = rect[rect[, "posterior"] == rect[orderedRect[1], "posterior"], "posterior"] # probs a more efficient way to do this
alpha = rep(alphaRange[i], length(rect[, 1]))
#prob = rep(1 / length(bestRect[, 1]), length(bestRect[, 1])) # "prob" is necessary because in some scenarios a given alpha will say that multiple rectangles are most likely. For example,
# when alpha = 0, all eligible rectangles are equally possible. Therefore, "prob" corresponds to 1/no. of unique "best" rectangles at that alpha level. This way even though if an alpha of 1
# and an alpha of 0 both predict the same rectangle to be the best, we will say that it corresponds to alpha = 1 because there were fewer possible rectangles to match with.
rectAlpha = cbind(rect, alpha) # add a column so we know what alpha generated each rectangle
colnames(rectAlpha) = c(colnames(rect), "alpha")
gridSearch = rbind(gridSearch, rectAlpha)
}
colnames(gridSearch) = c("x1", "y1", "x2", "y2", "posterior", "alpha", "prob") # name
return(gridSearch)
}
gridDist = alphaGridSearchDist(borders,obs)
match = gridDist[gridDist[,1] == 2 & gridDist[,2] == 2 & gridDist[,3] == 4 & gridDist[,4] == 4,]
View(match)
alphaGridSearchDist = function(borders,
observations,
alphaRange = seq(from = -1, to = 1, by = .2),
prior = "uniform") {
gridSearch = NULL
for (i in 1:length(alphaRange)) {
rect =  pedLearner(borders, observations, prior, alpha = alphaRange[i]) # generate all eligible rectangles (hypotheses)
#orderedRect =  order(rect[, "posterior"], decreasing = TRUE) # order from highest to lowest probability
#bestRect = rect[rect[, "posterior"] == rect[orderedRect[1], "posterior"], 1:4] # take the most probable rectangle, keeping only the coordinate information (columns 1:4)
#posterior = rect[rect[, "posterior"] == rect[orderedRect[1], "posterior"], "posterior"] # probs a more efficient way to do this
alpha = rep(alphaRange[i], length(rect[, 1]))
#prob = rep(1 / length(bestRect[, 1]), length(bestRect[, 1])) # "prob" is necessary because in some scenarios a given alpha will say that multiple rectangles are most likely. For example,
# when alpha = 0, all eligible rectangles are equally possible. Therefore, "prob" corresponds to 1/no. of unique "best" rectangles at that alpha level. This way even though if an alpha of 1
# and an alpha of 0 both predict the same rectangle to be the best, we will say that it corresponds to alpha = 1 because there were fewer possible rectangles to match with.
rectAlpha = cbind(rect, alpha) # add a column so we know what alpha generated each rectangle
colnames(rectAlpha) = c(colnames(rect), "alpha")
gridSearch = rbind(gridSearch, rectAlpha)
}
colnames(gridSearch) = c("x1", "y1", "x2", "y2", "posterior", "alpha", "prob") # name
return(gridSearch)
}
match = gridDist[gridDist[,1] == 2 & gridDist[,2] == 2 & gridDist[,3] == 4 & gridDist[,4] == 4,]
View(match)
gridDist = alphaGridSearchDist(borders,obs)
View(gridDist)
learn = pedLearner(borders,obs)
View(learn)
colnames(learn)
c(colnames(rect), "alpha")
c(colnames(learn), "alpha")
alphaGridSearchDist = function(borders,
observations,
alphaRange = seq(from = -1, to = 1, by = .2),
prior = "uniform") {
gridSearch = NULL
for (i in 1:length(alphaRange)) {
rect =  pedLearner(borders, observations, prior, alpha = alphaRange[i]) # generate all eligible rectangles (hypotheses)
#orderedRect =  order(rect[, "posterior"], decreasing = TRUE) # order from highest to lowest probability
#bestRect = rect[rect[, "posterior"] == rect[orderedRect[1], "posterior"], 1:4] # take the most probable rectangle, keeping only the coordinate information (columns 1:4)
#posterior = rect[rect[, "posterior"] == rect[orderedRect[1], "posterior"], "posterior"] # probs a more efficient way to do this
alpha = rep(alphaRange[i], length(rect[, 1]))
#prob = rep(1 / length(bestRect[, 1]), length(bestRect[, 1])) # "prob" is necessary because in some scenarios a given alpha will say that multiple rectangles are most likely. For example,
# when alpha = 0, all eligible rectangles are equally possible. Therefore, "prob" corresponds to 1/no. of unique "best" rectangles at that alpha level. This way even though if an alpha of 1
# and an alpha of 0 both predict the same rectangle to be the best, we will say that it corresponds to alpha = 1 because there were fewer possible rectangles to match with.
rectAlpha = cbind(rect, alpha) # add a column so we know what alpha generated each rectangle
gridSearch = rbind(gridSearch, rectAlpha)
}
#colnames(gridSearch) = c("x1", "y1", "x2", "y2", "posterior", "alpha", "prob") # name
colnames(rectAlpha) = c(colnames(rect), "alpha")
return(gridSearch)
}
gridSearch = NULL
alphaGridSearchDist = function(borders,
observations,
alphaRange = seq(from = -1, to = 1, by = .2),
prior = "uniform") {
gridSearch = NULL
for (i in 1:length(alphaRange)) {
rect =  pedLearner(borders, observations, prior, alpha = alphaRange[i]) # generate all eligible rectangles (hypotheses)
#orderedRect =  order(rect[, "posterior"], decreasing = TRUE) # order from highest to lowest probability
#bestRect = rect[rect[, "posterior"] == rect[orderedRect[1], "posterior"], 1:4] # take the most probable rectangle, keeping only the coordinate information (columns 1:4)
#posterior = rect[rect[, "posterior"] == rect[orderedRect[1], "posterior"], "posterior"] # probs a more efficient way to do this
alpha = rep(alphaRange[i], length(rect[, 1]))
#prob = rep(1 / length(bestRect[, 1]), length(bestRect[, 1])) # "prob" is necessary because in some scenarios a given alpha will say that multiple rectangles are most likely. For example,
# when alpha = 0, all eligible rectangles are equally possible. Therefore, "prob" corresponds to 1/no. of unique "best" rectangles at that alpha level. This way even though if an alpha of 1
# and an alpha of 0 both predict the same rectangle to be the best, we will say that it corresponds to alpha = 1 because there were fewer possible rectangles to match with.
rectAlpha = cbind(rect, alpha) # add a column so we know what alpha generated each rectangle
gridSearch = rbind(gridSearch, rectAlpha)
}
#colnames(gridSearch) = c("x1", "y1", "x2", "y2", "posterior", "alpha", "prob") # name
colnames(rectAlpha) = c(colnames(rect), "alpha")
return(gridSearch)
}
gridDist = alphaGridSearchDist(borders,obs)
View(gridDist)
match = gridDist[gridDist[,1] == 2 & gridDist[,2] == 2 & gridDist[,3] == 4 & gridDist[,4] == 4,]
View(match)
plot(obs)
rect(2,2,4,4)
obs
View(gridDist)
a05 = gridDist[gridDist[,"alpha"] == 0.5,]
View(gridDist)
a05 = gridDist[gridDist[,"alpha"] == "0.5",]
a05 = gridDist[gridDist[,"alpha"] == "0.6",]
a06 = gridDist[gridDist[,"alpha"] == "0.6",]
a0 = gridDist[gridDist[,"alpha"] == "0",]
a1 = a0 = gridDist[gridDist[,"alpha"] == "1",]
a1 = gridDist[gridDist[,"alpha"] == "1",]
a0 = gridDist[gridDist[,"alpha"] == "0",]
a06 = gridDist[gridDist[,"alpha"] == "0.6",]
plot(length(a0[,1], sort(a0[,"posterior"])))
plot(length(1:a0[,1], sort(a0[,"posterior"])))
plot(1:length(a0[,1], sort(a0[,"posterior"])))
plot(1:length(a0[,1]), sort(a0[,"posterior"]))
lines(1:length(a1[,1]), sort(a1[,"posterior"]))
plot(1:length(a1[,1]), sort(a1[,"posterior"]), "l")
lines(1:length(a0[,1]), sort(a0[,"posterior"]), "l")
lines(1:length(a06[,1]), sort(a06[,"posterior"]), "l")
lines(1:length(a06[,1]), sort(a06[,"posterior"]), "l", col = "green")
source("functions/samplingFunctions.R")
View(samplePosNeg)
rectSmall = c(2,2,4,4)
rectLarge = c(1,1,9,9)
rectSmall = c(2,2,4,4)
rectLarge = c(1,1,9,9)
obs = samplePosNeg(c(1,2), c(0,1), rectSmall)
debugonce(samplePosNeg)
obs = samplePosNeg(c(1,2), c(0,1), rectSmall)
rep("f",1)
debugonce(samplePosNeg)
obs = samplePosNeg(c(1,2), c(0,1), rectSmall)
source("functions/optimiseAlpha.R")
obs = generateObs(c(1,2), c(0,1), rectSmall)
View(obs)
obs = generateObs(c(1,2,3), c(0,1,3), rectSmall)
View(obs)
obs = generateObs(c(1,2,3), c(0,1,2), rectSmall)
